{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-18T18:03:36.922425Z",
     "iopub.status.busy": "2025-04-18T18:03:36.922192Z",
     "iopub.status.idle": "2025-04-18T18:03:39.921088Z",
     "shell.execute_reply": "2025-04-18T18:03:39.920293Z",
     "shell.execute_reply.started": "2025-04-18T18:03:36.922400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train1_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test0_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test_files.txt\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train3_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train3_id2name.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train_files.txt\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test1_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train0_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train3.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test1.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train1_id2name.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test0.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train2_id2name.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train2_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train0_id2name.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train1.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train4.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train4_id2name.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test1_id2name.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train2.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train0.h5\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/train4_id2file.json\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/shape_names.txt\n",
      "/kaggle/input/model40net/modelnet40_hdf5_2048/test0_id2name.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:03:39.922345Z",
     "iopub.status.busy": "2025-04-18T18:03:39.921927Z",
     "iopub.status.idle": "2025-04-18T18:03:46.093330Z",
     "shell.execute_reply": "2025-04-18T18:03:46.092570Z",
     "shell.execute_reply.started": "2025-04-18T18:03:39.922315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting robust-laplacian\n",
      "  Downloading robust_laplacian-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n",
      "Downloading robust_laplacian-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: robust-laplacian\n",
      "Successfully installed robust-laplacian-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install robust-laplacian numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T18:03:46.095527Z",
     "iopub.status.busy": "2025-04-18T18:03:46.095234Z",
     "iopub.status.idle": "2025-04-18T21:34:55.502725Z",
     "shell.execute_reply": "2025-04-18T21:34:55.501972Z",
     "shell.execute_reply.started": "2025-04-18T18:03:46.095508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using dataset path: /kaggle/input/model40net/modelnet40_hdf5_2048\n",
      "Found 5 training files: ['train3.h5', 'train1.h5', 'train4.h5', 'train2.h5', 'train0.h5']\n",
      "Reshaped points shape (9843, 2048, 3)\n",
      "Started computing Surface Variation (SV) efficiently\n",
      "Processed 0 / 9843 samples...\n",
      "Processed 100 / 9843 samples...\n",
      "Processed 200 / 9843 samples...\n",
      "Processed 300 / 9843 samples...\n",
      "Processed 400 / 9843 samples...\n",
      "Processed 500 / 9843 samples...\n",
      "Processed 600 / 9843 samples...\n",
      "Processed 700 / 9843 samples...\n",
      "Processed 800 / 9843 samples...\n",
      "Processed 900 / 9843 samples...\n",
      "Processed 1000 / 9843 samples...\n",
      "Processed 1100 / 9843 samples...\n",
      "Processed 1200 / 9843 samples...\n",
      "Processed 1300 / 9843 samples...\n",
      "Processed 1400 / 9843 samples...\n",
      "Processed 1500 / 9843 samples...\n",
      "Processed 1600 / 9843 samples...\n",
      "Processed 1700 / 9843 samples...\n",
      "Processed 1800 / 9843 samples...\n",
      "Processed 1900 / 9843 samples...\n",
      "Processed 2000 / 9843 samples...\n",
      "Processed 2100 / 9843 samples...\n",
      "Processed 2200 / 9843 samples...\n",
      "Processed 2300 / 9843 samples...\n",
      "Processed 2400 / 9843 samples...\n",
      "Processed 2500 / 9843 samples...\n",
      "Processed 2600 / 9843 samples...\n",
      "Processed 2700 / 9843 samples...\n",
      "Processed 2800 / 9843 samples...\n",
      "Processed 2900 / 9843 samples...\n",
      "Processed 3000 / 9843 samples...\n",
      "Processed 3100 / 9843 samples...\n",
      "Processed 3200 / 9843 samples...\n",
      "Processed 3300 / 9843 samples...\n",
      "Processed 3400 / 9843 samples...\n",
      "Processed 3500 / 9843 samples...\n",
      "Processed 3600 / 9843 samples...\n",
      "Processed 3700 / 9843 samples...\n",
      "Processed 3800 / 9843 samples...\n",
      "Processed 3900 / 9843 samples...\n",
      "Processed 4000 / 9843 samples...\n",
      "Processed 4100 / 9843 samples...\n",
      "Processed 4200 / 9843 samples...\n",
      "Processed 4300 / 9843 samples...\n",
      "Processed 4400 / 9843 samples...\n",
      "Processed 4500 / 9843 samples...\n",
      "Processed 4600 / 9843 samples...\n",
      "Processed 4700 / 9843 samples...\n",
      "Processed 4800 / 9843 samples...\n",
      "Processed 4900 / 9843 samples...\n",
      "Processed 5000 / 9843 samples...\n",
      "Processed 5100 / 9843 samples...\n",
      "Processed 5200 / 9843 samples...\n",
      "Processed 5300 / 9843 samples...\n",
      "Processed 5400 / 9843 samples...\n",
      "Processed 5500 / 9843 samples...\n",
      "Processed 5600 / 9843 samples...\n",
      "Processed 5700 / 9843 samples...\n",
      "Processed 5800 / 9843 samples...\n",
      "Processed 5900 / 9843 samples...\n",
      "Processed 6000 / 9843 samples...\n",
      "Processed 6100 / 9843 samples...\n",
      "Processed 6200 / 9843 samples...\n",
      "Processed 6300 / 9843 samples...\n",
      "Processed 6400 / 9843 samples...\n",
      "Processed 6500 / 9843 samples...\n",
      "Processed 6600 / 9843 samples...\n",
      "Processed 6700 / 9843 samples...\n",
      "Processed 6800 / 9843 samples...\n",
      "Processed 6900 / 9843 samples...\n",
      "Processed 7000 / 9843 samples...\n",
      "Processed 7100 / 9843 samples...\n",
      "Processed 7200 / 9843 samples...\n",
      "Processed 7300 / 9843 samples...\n",
      "Processed 7400 / 9843 samples...\n",
      "Processed 7500 / 9843 samples...\n",
      "Processed 7600 / 9843 samples...\n",
      "Processed 7700 / 9843 samples...\n",
      "Processed 7800 / 9843 samples...\n",
      "Processed 7900 / 9843 samples...\n",
      "Processed 8000 / 9843 samples...\n",
      "Processed 8100 / 9843 samples...\n",
      "Processed 8200 / 9843 samples...\n",
      "Processed 8300 / 9843 samples...\n",
      "Processed 8400 / 9843 samples...\n",
      "Processed 8500 / 9843 samples...\n",
      "Processed 8600 / 9843 samples...\n",
      "Processed 8700 / 9843 samples...\n",
      "Processed 8800 / 9843 samples...\n",
      "Processed 8900 / 9843 samples...\n",
      "Processed 9000 / 9843 samples...\n",
      "Processed 9100 / 9843 samples...\n",
      "Processed 9200 / 9843 samples...\n",
      "Processed 9300 / 9843 samples...\n",
      "Processed 9400 / 9843 samples...\n",
      "Processed 9500 / 9843 samples...\n",
      "Processed 9600 / 9843 samples...\n",
      "Processed 9700 / 9843 samples...\n",
      "Processed 9800 / 9843 samples...\n",
      "Vatiations:\n",
      " [[0.1231285  0.07999143 0.13746932 ... 0.08312277 0.08227643 0.04456517]\n",
      " [0.12486085 0.10423382 0.09187645 ... 0.11629326 0.13611002 0.19361731]\n",
      " [0.14884427 0.0810877  0.08848935 ... 0.05608104 0.051013   0.07179558]\n",
      " [0.10132378 0.16771325 0.12935191 ... 0.14917272 0.08411141 0.01987389]\n",
      " [0.09164036 0.2160854  0.20303679 ... 0.02479466 0.15993541 0.13956559]] \n",
      "Variation length (no. of samples): 9843 \n",
      " num of points in each sample: 2048\n",
      "Done computing surface variations\n",
      "Initializing active set sample-wise using FPS...\n",
      "Done loading remainder set.\n",
      "Optimizing GP hyperparameters...\n",
      "Fitting a single GP model for all samples...\n",
      "Optimized GP hyperparameters: (0.73, 2.32, -1.72)\n",
      "Started adding points based on selection criteria...\n",
      "Using fixed GP hyperparameters: [0.73, 2.32, -1.72]\n",
      "Started adding points based on selection criteria...\n",
      "Simplification complete. \n",
      "Simplified Point Cloud Shape: (9843, 1536, 3)\n",
      "Loaded 9843 training samples\n",
      "Starting training...\n",
      "Epoch [1/75]\n",
      "Train Loss: 1.6836, Train Accuracy: 0.6780\n",
      "Epoch [2/75]\n",
      "Train Loss: 1.3548, Train Accuracy: 0.7811\n",
      "Epoch [3/75]\n",
      "Train Loss: 1.2669, Train Accuracy: 0.8155\n",
      "Epoch [4/75]\n",
      "Train Loss: 1.2063, Train Accuracy: 0.8338\n",
      "Epoch [5/75]\n",
      "Train Loss: 1.1710, Train Accuracy: 0.8500\n",
      "Epoch [6/75]\n",
      "Train Loss: 1.1452, Train Accuracy: 0.8510\n",
      "Epoch [7/75]\n",
      "Train Loss: 1.1204, Train Accuracy: 0.8654\n",
      "Epoch [8/75]\n",
      "Train Loss: 1.1020, Train Accuracy: 0.8706\n",
      "Epoch [9/75]\n",
      "Train Loss: 1.0859, Train Accuracy: 0.8745\n",
      "Epoch [10/75]\n",
      "Train Loss: 1.0652, Train Accuracy: 0.8810\n",
      "Epoch [11/75]\n",
      "Train Loss: 1.0516, Train Accuracy: 0.8868\n",
      "Epoch [12/75]\n",
      "Train Loss: 1.0403, Train Accuracy: 0.8892\n",
      "Epoch [13/75]\n",
      "Train Loss: 1.0304, Train Accuracy: 0.8937\n",
      "Epoch [14/75]\n",
      "Train Loss: 1.0156, Train Accuracy: 0.8981\n",
      "Epoch [15/75]\n",
      "Train Loss: 1.0047, Train Accuracy: 0.9051\n",
      "Epoch [16/75]\n",
      "Train Loss: 1.0012, Train Accuracy: 0.9051\n",
      "Epoch [17/75]\n",
      "Train Loss: 0.9950, Train Accuracy: 0.9047\n",
      "Epoch [18/75]\n",
      "Train Loss: 0.9777, Train Accuracy: 0.9130\n",
      "Epoch [19/75]\n",
      "Train Loss: 0.9763, Train Accuracy: 0.9143\n",
      "Epoch [20/75]\n",
      "Train Loss: 0.9683, Train Accuracy: 0.9153\n",
      "Epoch [21/75]\n",
      "Train Loss: 0.9549, Train Accuracy: 0.9213\n",
      "Epoch [22/75]\n",
      "Train Loss: 0.9465, Train Accuracy: 0.9237\n",
      "Epoch [23/75]\n",
      "Train Loss: 0.9364, Train Accuracy: 0.9260\n",
      "Epoch [24/75]\n",
      "Train Loss: 0.9356, Train Accuracy: 0.9255\n",
      "Epoch [25/75]\n",
      "Train Loss: 0.9320, Train Accuracy: 0.9300\n",
      "Epoch [26/75]\n",
      "Train Loss: 0.9230, Train Accuracy: 0.9330\n",
      "Epoch [27/75]\n",
      "Train Loss: 0.9202, Train Accuracy: 0.9317\n",
      "Epoch [28/75]\n",
      "Train Loss: 0.9116, Train Accuracy: 0.9362\n",
      "Epoch [29/75]\n",
      "Train Loss: 0.9096, Train Accuracy: 0.9371\n",
      "Epoch [30/75]\n",
      "Train Loss: 0.9013, Train Accuracy: 0.9398\n",
      "Epoch [31/75]\n",
      "Train Loss: 0.8921, Train Accuracy: 0.9431\n",
      "Epoch [32/75]\n",
      "Train Loss: 0.8915, Train Accuracy: 0.9427\n",
      "Epoch [33/75]\n",
      "Train Loss: 0.8816, Train Accuracy: 0.9465\n",
      "Epoch [34/75]\n",
      "Train Loss: 0.8756, Train Accuracy: 0.9484\n",
      "Epoch [35/75]\n",
      "Train Loss: 0.8738, Train Accuracy: 0.9521\n",
      "Epoch [36/75]\n",
      "Train Loss: 0.8712, Train Accuracy: 0.9528\n",
      "Epoch [37/75]\n",
      "Train Loss: 0.8634, Train Accuracy: 0.9541\n",
      "Epoch [38/75]\n",
      "Train Loss: 0.8608, Train Accuracy: 0.9562\n",
      "Epoch [39/75]\n",
      "Train Loss: 0.8543, Train Accuracy: 0.9584\n",
      "Epoch [40/75]\n",
      "Train Loss: 0.8519, Train Accuracy: 0.9602\n",
      "Epoch [41/75]\n",
      "Train Loss: 0.8515, Train Accuracy: 0.9587\n",
      "Epoch [42/75]\n",
      "Train Loss: 0.8451, Train Accuracy: 0.9606\n",
      "Epoch [43/75]\n",
      "Train Loss: 0.8425, Train Accuracy: 0.9614\n",
      "Epoch [44/75]\n",
      "Train Loss: 0.8330, Train Accuracy: 0.9646\n",
      "Epoch [45/75]\n",
      "Train Loss: 0.8335, Train Accuracy: 0.9668\n",
      "Epoch [46/75]\n",
      "Train Loss: 0.8276, Train Accuracy: 0.9666\n",
      "Epoch [47/75]\n",
      "Train Loss: 0.8264, Train Accuracy: 0.9675\n",
      "Epoch [48/75]\n",
      "Train Loss: 0.8213, Train Accuracy: 0.9688\n",
      "Epoch [49/75]\n",
      "Train Loss: 0.8200, Train Accuracy: 0.9698\n",
      "Epoch [50/75]\n",
      "Train Loss: 0.8220, Train Accuracy: 0.9681\n",
      "Epoch [51/75]\n",
      "Train Loss: 0.8155, Train Accuracy: 0.9702\n",
      "Epoch [52/75]\n",
      "Train Loss: 0.8115, Train Accuracy: 0.9726\n",
      "Epoch [53/75]\n",
      "Train Loss: 0.8104, Train Accuracy: 0.9721\n",
      "Epoch [54/75]\n",
      "Train Loss: 0.8042, Train Accuracy: 0.9738\n",
      "Epoch [55/75]\n",
      "Train Loss: 0.8042, Train Accuracy: 0.9737\n",
      "Epoch [56/75]\n",
      "Train Loss: 0.8012, Train Accuracy: 0.9765\n",
      "Epoch [57/75]\n",
      "Train Loss: 0.7999, Train Accuracy: 0.9762\n",
      "Epoch [58/75]\n",
      "Train Loss: 0.7984, Train Accuracy: 0.9773\n",
      "Epoch [59/75]\n",
      "Train Loss: 0.7944, Train Accuracy: 0.9789\n",
      "Epoch [60/75]\n",
      "Train Loss: 0.7919, Train Accuracy: 0.9789\n",
      "Epoch [61/75]\n",
      "Train Loss: 0.7885, Train Accuracy: 0.9789\n",
      "Epoch [62/75]\n",
      "Train Loss: 0.7918, Train Accuracy: 0.9783\n",
      "Epoch [63/75]\n",
      "Train Loss: 0.7896, Train Accuracy: 0.9793\n",
      "Epoch [64/75]\n",
      "Train Loss: 0.7897, Train Accuracy: 0.9793\n",
      "Epoch [65/75]\n",
      "Train Loss: 0.7842, Train Accuracy: 0.9821\n",
      "Epoch [66/75]\n",
      "Train Loss: 0.7839, Train Accuracy: 0.9837\n",
      "Epoch [67/75]\n",
      "Train Loss: 0.7874, Train Accuracy: 0.9793\n",
      "Epoch [68/75]\n",
      "Train Loss: 0.7840, Train Accuracy: 0.9814\n",
      "Epoch [69/75]\n",
      "Train Loss: 0.7840, Train Accuracy: 0.9811\n",
      "Epoch [70/75]\n",
      "Train Loss: 0.7828, Train Accuracy: 0.9827\n",
      "Epoch [71/75]\n",
      "Train Loss: 0.7846, Train Accuracy: 0.9823\n",
      "Epoch [72/75]\n",
      "Train Loss: 0.7811, Train Accuracy: 0.9826\n",
      "Epoch [73/75]\n",
      "Train Loss: 0.7835, Train Accuracy: 0.9821\n",
      "Epoch [74/75]\n",
      "Train Loss: 0.7779, Train Accuracy: 0.9834\n",
      "Epoch [75/75]\n",
      "Train Loss: 0.7809, Train Accuracy: 0.9832\n",
      "Training complete!\n",
      "Model saved to pointnet_modelnet40.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from scipy.linalg import eigh\n",
    "from scipy.spatial import distance\n",
    "from robust_laplacian import point_cloud_laplacian\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KDTree\n",
    "from scipy.sparse.linalg import eigsh \n",
    "\n",
    "# Define constants\n",
    "D = 3  # Dimensionality\n",
    "M = 1536  # Simplified point cloud size\n",
    "k_init = 256  # Initial points for FPS\n",
    "k_add = 256  # Points added per iteration\n",
    "k_opt = 4  # Points for optimizing GP hyperparameters\n",
    "\n",
    "# Define the FPS function from paste.txt\n",
    "def gp_pcs_simplify(point_cloud, num_points):\n",
    "    \"\"\"\n",
    "    Simplify a point cloud using Farthest Point Sampling.\n",
    "    \"\"\"\n",
    "    simplified_cloud = [point_cloud[np.random.choice(point_cloud.shape[0])]]\n",
    "    \n",
    "    for _ in range(num_points - 1):\n",
    "        dists = np.linalg.norm(point_cloud - simplified_cloud[-1], axis=1)\n",
    "        next_point_idx = np.argmax(dists)\n",
    "        simplified_cloud.append(point_cloud[next_point_idx])\n",
    "        point_cloud = np.delete(point_cloud, next_point_idx, axis=0)\n",
    "    \n",
    "    return np.array(simplified_cloud)\n",
    "\n",
    "class GaussianProcess:\n",
    "    def __init__(self, kernel, noise_var=1e-6):\n",
    "        self.kernel = kernel\n",
    "        self.sigma_y2 = noise_var**2\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.K = self.kernel(X, X) + self.sigma_y2 * np.eye(len(X))\n",
    "        self.K += np.eye(len(self.K)) * 1e-6\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        K_test = self.kernel(X_test, self.X_train)\n",
    "        K_inv = np.linalg.inv(self.K)\n",
    "        mean = np.dot(K_test, np.dot(K_inv, self.y_train))\n",
    "    \n",
    "        # Extract diagonal of covariance matrix\n",
    "        var = self.kernel(X_test, X_test) - np.dot(K_test, np.dot(K_inv, K_test.T))\n",
    "        var = np.maximum(np.diag(var), 1e-6)  # Take only diagonal and ensure positive values\n",
    "    \n",
    "        return mean, var\n",
    "    def log_marginal_likelihood(self, theta):\n",
    "        sigma2, kappa, nu = theta\n",
    "        self.kernel.theta = theta\n",
    "        K = self.kernel(self.X_train, self.X_train) + self.sigma_y2 * np.eye(len(self.X_train))\n",
    "        \n",
    "        # Enhanced numerical stability\n",
    "        jitter = 1e-3  # Increased from 1e-4\n",
    "        K += np.eye(K.shape[0]) * jitter\n",
    "        \n",
    "        try:\n",
    "            # Use Cholesky decomposition instead of direct inverse\n",
    "            L = np.linalg.cholesky(K)\n",
    "            alpha = np.linalg.solve(L.T, np.linalg.solve(L, self.y_train))\n",
    "            log_det = 2 * np.sum(np.log(np.diag(L)))\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Return -inf for invalid parameters\n",
    "            return -np.inf\n",
    "        \n",
    "        # Stable likelihood calculation\n",
    "        log_likelihood = (\n",
    "            -0.5 * np.dot(self.y_train.T, alpha)\n",
    "            - 0.5 * log_det\n",
    "            - len(self.y_train)/2 * np.log(2*np.pi)\n",
    "        )\n",
    "        \n",
    "        # Prevent invalid values\n",
    "        if not np.isfinite(log_likelihood):\n",
    "            return -np.inf\n",
    "            \n",
    "        return log_likelihood.item()\n",
    "\n",
    "\n",
    "class RiemannianKernel:\n",
    "    def __init__(self, sigma_y=0.73, kappa=2.32, nu=-1.72, eigenvalues=None, eigenfunctions=None):\n",
    "        self.sigma_y = sigma_y\n",
    "        self.kappa = kappa\n",
    "        self.nu = nu\n",
    "        self.theta = (sigma_y, kappa, nu)\n",
    "        self.Cv = 1.0  # Normalizing constant\n",
    "        self.eigenvalues = eigenvalues\n",
    "        self.eigenfunctions = eigenfunctions\n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        if self.eigenvalues is None or self.eigenfunctions is None:\n",
    "            raise ValueError(\"Eigenvalues and eigenfunctions must be provided.\")\n",
    "        \n",
    "        sigma_y, kappa, nu = self.theta\n",
    "        result = 0\n",
    "        for n in range(len(self.eigenvalues)):\n",
    "            result += ((2 * nu / kappa**2) + self.eigenvalues[n])**(-nu - 1.5) * self.eigenfunctions[n, 0] * self.eigenfunctions[n, 0]\n",
    "        return (sigma_y**2 / self.Cv) * result\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def estimate_eigenvalues_and_eigenfunctions(vertices, faces, num_eigenvalues=1):\n",
    "    \"\"\"\n",
    "    Compute eigenvalues and eigenfunctions, ensuring k_neighbors <= available points.\n",
    "    \"\"\"\n",
    "    num_points = len(vertices)\n",
    "\n",
    "    # Dynamically set k_neighbors to avoid exceeding available points\n",
    "    k_neighbors = min(16, num_points - 1)  # Ensure at least 1 neighbor\n",
    "\n",
    "    # Compute the Laplacian matrix safely\n",
    "    L, M = point_cloud_laplacian(vertices, n_neighbors=k_neighbors)\n",
    "\n",
    "    L = csr_matrix(L)  # Convert to sparse matrix\n",
    "    \n",
    "    try:\n",
    "        U, s, Vt = svds(L, k=min(num_eigenvalues, len(L.toarray()) - 1))  # Avoid exceeding matrix size\n",
    "    except Exception as e:\n",
    "        print(f\"SVD computation failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    return s, U\n",
    "\n",
    "def optimize_gp_hyperparameters(gp, X_opt, y_opt):\n",
    "    from scipy.optimize import minimize\n",
    "    \n",
    "    def neg_log_likelihood(theta):\n",
    "        return -gp.log_marginal_likelihood(theta)  # Ensure it's a scalar\n",
    "\n",
    "    # Modified optimization configuration\n",
    "    result = minimize(\n",
    "        neg_log_likelihood,\n",
    "        x0=[0.3, 1.8, 1.2],\n",
    "        method=\"Nelder-Mead\",\n",
    "        options={\n",
    "            \"maxiter\": 200,\n",
    "            \"disp\": True,\n",
    "            \"adaptive\": True,\n",
    "            \"xatol\": 1e-3,  # Relaxed tolerance\n",
    "            \"fatol\": 0.1    # Increased from 0.05\n",
    "        }\n",
    "    )\n",
    "    return result.x\n",
    "    \n",
    "def regularize_cov_matrix(cov_matrix, regularization_strength=1e-4):\n",
    "    return cov_matrix + regularization_strength * np.eye(cov_matrix.shape[0], dtype=np.float32)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "def compute_surface_variation(points):\n",
    "    \"\"\"\n",
    "    Computes surface variation for each point in each sample efficiently.\n",
    "    :param points: NumPy array of shape (n_samples, 3, 2048), containing point clouds.\n",
    "    :return: NumPy array of shape (n_samples, 2048) containing surface variations.\n",
    "    \"\"\"\n",
    "    print(\"Started computing Surface Variation (SV) efficiently\")\n",
    "    \n",
    "    points_array = np.array(points)  # Shape (n_samples, 3, 2048)\n",
    "    points_array = np.transpose(points_array, (0, 2, 1))  # Change to (n_samples, 2048, 3)\n",
    "    \n",
    "    k_neighbors = 35  # Reduce neighborhood size for efficiency\n",
    "    num_samples, num_points, _ = points_array.shape  # (n_samples, 2048, 3)\n",
    "\n",
    "    variations = np.zeros((num_samples, num_points))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = points_array[i]  # Shape (2048, 3)\n",
    "        kdtree = KDTree(sample)  # KDTree for current sample\n",
    "        _, idxs = kdtree.query(sample, k=k_neighbors + 1)  # Shape (2048, k+1)\n",
    "        neighbors = sample[idxs[:, 1:]]  # Exclude self, shape (2048, k, 3)\n",
    "\n",
    "        # Compute centroids for all neighborhoods at once\n",
    "        centroids = np.mean(neighbors, axis=1, keepdims=True)  # Shape (2048, 1, 3)\n",
    "        centered_neighbors = neighbors - centroids  # Shape (2048, k, 3)\n",
    "\n",
    "        # Compute covariance matrices efficiently using broadcasting (not PCA)\n",
    "        cov_matrices = np.einsum('ijk,ijl->ikl', centered_neighbors, centered_neighbors) / (k_neighbors - 1)  # (2048, 3, 3)\n",
    "\n",
    "        # Compute only the smallest eigenvalue for each point's covariance matrix\n",
    "        eigenvalues = np.array([eigh(cov, eigvals_only=True) for cov in cov_matrices])  # Shape (2048, 3)\n",
    "        min_eigenvalues = eigenvalues[:, 0]  # Smallest eigenvalue for each point\n",
    "\n",
    "        # Compute surface variation\n",
    "        variations[i, :] = min_eigenvalues / np.sum(eigenvalues, axis=1)  # Normalize by total variance\n",
    "\n",
    "        if i % 100 == 0:  # Reduce print frequency\n",
    "            print(f\"Processed {i} / {num_samples} samples...\")\n",
    "    print(\"Vatiations:\\n\",variations[:5],\"\\nVariation length (no. of samples):\",len(variations),\"\\n num of points in each sample:\",len(variations[0]))\n",
    "    print(\"Done computing surface variations\")\n",
    "    return variations  # Shape (n_samples, 2048)\n",
    "\n",
    "def get_neighbors(point, points, k=32):\n",
    "    # Convert points to a NumPy array for array indexing\n",
    "    points_array = np.array(points)\n",
    "    \n",
    "    # For simplicity, use Euclidean distance to find neighbors\n",
    "    dists = euclidean_distances([point], points_array)[0]\n",
    "    idxs = np.argsort(dists)[:k+1]\n",
    "    return points_array[idxs[1:]]\n",
    "\n",
    "def compute_cov_matrix(points):\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "    return np.dot(centered_points.T, centered_points)\n",
    "\n",
    "def greedy_subset_of_data(points, surface_variations, M, k_init, k_add):\n",
    "    \"\"\"\n",
    "    Implements greedy subset selection sample-wise, following the GP-PCS research paper.\n",
    "    :param points: (n, 2048, 3) NumPy array of point clouds.\n",
    "    :param surface_variations: (n, 2048) NumPy array of surface variations.\n",
    "    :param M: Number of points to retain in the simplified set per sample.\n",
    "    :param k_init: Initial number of points selected per sample using FPS.\n",
    "    :param k_add: Points added per iteration.\n",
    "    :return: (n, M, 3) NumPy array of simplified point clouds.\n",
    "    \"\"\"\n",
    "    n, num_points, _ = points.shape  # (n, 2048, 3)\n",
    "\n",
    "    print(\"Initializing active set sample-wise using FPS...\")\n",
    "    active_set = [gp_pcs_simplify(points[i], k_init).tolist() for i in range(n)]  # List of lists\n",
    "\n",
    "    # Initialize as NumPy arrays instead of lists\n",
    "    remainder_set = [points[i].copy() for i in range(n)]  # Keep as NumPy arrays\n",
    "    remainder_variations = [surface_variations[i].copy() for i in range(n)]  # NumPy arrays\n",
    "\n",
    "    # ... existing FPS initialization code ...\n",
    "\n",
    "    # Modified mask application\n",
    "    for i in range(n):\n",
    "        kdtree = KDTree(points[i])\n",
    "        active_indices = kdtree.query(np.array(active_set[i]), k=1)[1].flatten()\n",
    "\n",
    "        # Create boolean mask for remainder points\n",
    "        mask = np.ones(points[i].shape[0], dtype=bool)\n",
    "        mask[active_indices] = False\n",
    "\n",
    "        # Apply mask to NumPy arrays\n",
    "        remainder_set[i] = points[i][mask]\n",
    "        remainder_variations[i] = surface_variations[i][mask]\n",
    "\n",
    "    print(\"Done loading remainder set.\")\n",
    "    print(\"Optimizing GP hyperparameters...\")\n",
    "\n",
    "    # Select P_opt for GP Optimization\n",
    "    P_opt = np.array([gp_pcs_simplify(points[i], k_opt) for i in range(n)])  # (n, k_opt, 3)\n",
    "    eigenvalues_list, eigenfunctions_list = [], []\n",
    "\n",
    "    for i in range(n):\n",
    "        vertices = P_opt[i]\n",
    "        faces = np.random.randint(0, len(vertices), size=(len(vertices), 3))\n",
    "        eigenvalues, eigenfunctions = estimate_eigenvalues_and_eigenfunctions(vertices, faces)\n",
    "        eigenvalues_list.append(eigenvalues)\n",
    "        eigenfunctions_list.append(eigenfunctions)\n",
    "\n",
    "    print(\"Fitting a single GP model for all samples...\")\n",
    "    mean_eigenvalues = np.mean(np.array(eigenvalues_list), axis=0)\n",
    "    mean_eigenfunctions = np.mean(np.array(eigenfunctions_list), axis=0)\n",
    "\n",
    "    gp = GaussianProcess(RiemannianKernel(eigenvalues=mean_eigenvalues, eigenfunctions=mean_eigenfunctions))\n",
    "\n",
    "    P_opt_flat = P_opt.reshape(-1, 3)\n",
    "    y_opt_flat = surface_variations[:, :k_opt].reshape(-1)\n",
    "\n",
    "    # gp.fit(P_opt_flat, y_opt_flat)\n",
    "\n",
    "    # theta_opt = optimize_gp_hyperparameters(gp, P_opt_flat, y_opt_flat)\n",
    "    # gp.kernel.theta = theta_opt\n",
    "    print(\"Optimized GP hyperparameters:\", gp.kernel.theta)\n",
    "    print(\"Started adding points based on selection criteria...\")\n",
    "    # # **Greedy Selection Loop** (Optimized)\n",
    "    gp.fit(P_opt_flat, y_opt_flat)\n",
    "\n",
    "    # theta_opt = optimize_gp_hyperparameters(gp, P_opt_flat, y_opt_flat)  # <-- Commented out\n",
    "    gp.kernel.theta = [0.73, 2.32, -1.72]  # <-- Use fixed hyperparameters\n",
    "    print(\"Using fixed GP hyperparameters:\", gp.kernel.theta)\n",
    "    print(\"Started adding points based on selection criteria...\")\n",
    "\n",
    "    max_iterations = 14400000\n",
    "    iteration = 0\n",
    "    batch_size = 4  # Start with 4, adjust based on memory\n",
    "    kdtrees = [KDTree(active_set[i]) for i in range(n)]\n",
    "    completed = [False]*n\n",
    "    remainder_masks = [np.ones(len(r), dtype=bool) for r in remainder_set]\n",
    "    \n",
    "    while sum(completed) < n and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Progress tracking\n",
    "        if iteration % 20 == 0:\n",
    "            active_sizes = [len(a) for a in active_set]\n",
    "            remaining = [np.sum(m) for m in remainder_masks]\n",
    "            # print(f\"Iter {iteration}: Active {active_sizes} | Remaining {remaining}\")\n",
    "    \n",
    "        # Process in batches\n",
    "        for batch_start in range(0, n, batch_size):\n",
    "            batch_samples = range(batch_start, min(batch_start+batch_size, n))\n",
    "            \n",
    "            # Batch Processing\n",
    "            batch_points = []\n",
    "            batch_variations = []\n",
    "            sample_sizes = []\n",
    "            \n",
    "            # Collect data for current batch\n",
    "            for i in batch_samples:\n",
    "                if not completed[i]:\n",
    "                    valid_indices = np.where(remainder_masks[i])[0]\n",
    "                    batch_points.append(remainder_set[i][valid_indices])\n",
    "                    batch_variations.append(remainder_variations[i][valid_indices])\n",
    "                    sample_sizes.append(len(valid_indices))\n",
    "                else:\n",
    "                    sample_sizes.append(0)\n",
    "            \n",
    "            if sum(sample_sizes) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Concatenate and fit GP\n",
    "            batch_points_concat = np.concatenate(batch_points)\n",
    "            batch_variations_concat = np.concatenate(batch_variations)\n",
    "            \n",
    "            # Critical Fix: Fit GP on current active set\n",
    "            active_points = np.concatenate([active_set[i] for i in batch_samples if not completed[i]])\n",
    "            active_variations = np.concatenate([surface_variations[i][:len(active_set[i])] \n",
    "                                              for i in batch_samples if not completed[i]])\n",
    "            gp.fit(active_points, active_variations)  # Update model with current active set\n",
    "            \n",
    "            # Get predictions\n",
    "            batch_mean, batch_var = gp.predict(batch_points_concat)\n",
    "            \n",
    "            # Process individual samples\n",
    "            ptr = 0\n",
    "            for i_idx, i in enumerate(batch_samples):\n",
    "                if completed[i] or sample_sizes[i_idx] == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Slice predictions\n",
    "                end = ptr + sample_sizes[i_idx]\n",
    "                mean = batch_mean[ptr:end]\n",
    "                var = batch_var[ptr:end]\n",
    "                ptr = end\n",
    "                \n",
    "                # Get current valid indices\n",
    "                valid_indices = np.where(remainder_masks[i])[0]\n",
    "                \n",
    "                # Size validation\n",
    "                if len(mean) != len(valid_indices):\n",
    "                    min_size = min(len(mean), len(valid_indices))\n",
    "                    mean = mean[:min_size]\n",
    "                    var = var[:min_size]\n",
    "                    valid_indices = valid_indices[:min_size]\n",
    "                \n",
    "                # Get corresponding variations\n",
    "                current_variations = remainder_variations[i][valid_indices]\n",
    "                \n",
    "                # Selection criterion\n",
    "                selection = np.sqrt(var) + np.abs(mean - current_variations)\n",
    "                valid_k = min(k_add, len(selection))\n",
    "                \n",
    "                if valid_k == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Select top candidates\n",
    "                selected = np.argpartition(selection, valid_k-1)[:valid_k]\n",
    "                selected_indices = valid_indices[selected]\n",
    "                \n",
    "                # Update sets\n",
    "                add_count = min(valid_k, M - len(active_set[i]))\n",
    "                active_set[i] = np.vstack([active_set[i], remainder_set[i][selected_indices[:add_count]]])\n",
    "                \n",
    "                # Update mask\n",
    "                remainder_masks[i][selected_indices[:add_count]] = False\n",
    "                \n",
    "                # Update KDTree if needed\n",
    "                if add_count > 0:\n",
    "                    kdtrees[i] = KDTree(active_set[i])\n",
    "                \n",
    "                # Check completion\n",
    "                if len(active_set[i]) >= M:\n",
    "                    completed[i] = True\n",
    "\n",
    "\n",
    "    print(\"Simplification complete. \")\n",
    "\n",
    "\n",
    "    # Convert back to a NumPy array before returning\n",
    "    return np.array([np.array(a[:M]) for a in active_set])  # Ensure (n, M, 3)\n",
    "\n",
    "class PointNetFeature(nn.Module):\n",
    "    def __init__(self, global_feature=True, feature_transform=False):\n",
    "        super(PointNetFeature, self).__init__()\n",
    "        self.global_feature = global_feature\n",
    "        self.feature_transform = feature_transform\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        # Optional feature transformation\n",
    "        if self.feature_transform:\n",
    "            self.fstn = FeatureTransformNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        n_pts = x.size()[2]\n",
    "        \n",
    "        # First convolution block\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Optional feature transformation\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat)\n",
    "            x = x.transpose(2, 1)\n",
    "        \n",
    "        # Additional convolution blocks\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        return x.view(-1, 1024)\n",
    "\n",
    "class PointNetClassification(nn.Module):\n",
    "    def __init__(self, num_classes=40, feature_transform=False):\n",
    "        super(PointNetClassification, self).__init__()\n",
    "        \n",
    "        # Feature extraction\n",
    "        self.feature_extraction = PointNetFeature(\n",
    "            global_feature=True, \n",
    "            feature_transform=feature_transform\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Batch normalization and dropout\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract global features\n",
    "        x = self.feature_extraction(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "class FeatureTransformNet(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(FeatureTransformNet, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Convolutional blocks\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global max pooling\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.bn4(self.fc1(x.squeeze(-1))))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # Create identity matrix\n",
    "        iden = torch.eye(x.size(-1) // x.size(0)).view(1, -1).repeat(batch_size, 1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(batch_size, -1, x.size(-1) // batch_size)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ModelNet40Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, directory, train=True):\n",
    "        \"\"\"\n",
    "        Load ModelNet40 dataset from HDF5 files\n",
    "        Args:\n",
    "            directory (str): Path to directory containing HDF5 files\n",
    "            train (bool): Whether to load training or test data\n",
    "        \"\"\"\n",
    "        self.points1 = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Find all HDF5 files in the directory with \"train\" in the filename\n",
    "        h5_files = []\n",
    "        for f in os.listdir(directory):\n",
    "            if f.endswith('.h5') and ('train' in f.lower()):\n",
    "                h5_files.append(f)\n",
    "        \n",
    "        print(f\"Found {len(h5_files)} training files: {h5_files}\")\n",
    "        \n",
    "        for filename in h5_files:\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with h5py.File(filepath, 'r') as f:\n",
    "                # Assume the first dataset is points, second is labels\n",
    "                points = f['data'][:]\n",
    "                labels = f['label'][:]\n",
    "                \n",
    "                self.points1.append(points)\n",
    "                self.labels.append(labels)\n",
    "        \n",
    "        # Concatenate data\n",
    "        self.points1 = np.concatenate(self.points1, axis=0)\n",
    "        self.labels = np.concatenate(self.labels, axis=0)\n",
    "        \n",
    "        # Flatten labels\n",
    "        self.labels = self.labels.squeeze()\n",
    "        \n",
    "        # Transpose points to match model input (C, N) format\n",
    "        self.points1 = torch.from_numpy(self.points1.transpose(0, 2, 1)).float()\n",
    "        self.labels = torch.from_numpy(self.labels).long()\n",
    "\n",
    "        self.points1 = self.points1.numpy()  # Convert torch tensor to NumPy array\n",
    "        # Reshape points from (9843, 3, 2048) to (9843, 2048, 3)\n",
    "        reshaped_points = np.transpose(self.points1, (0, 2, 1))\n",
    "        print(\"Reshaped points shape\",reshaped_points.shape)\n",
    "        \n",
    "        # Compute surface variations\n",
    "        surface_variations = compute_surface_variation(self.points1)\n",
    "        \n",
    "        # Simplify point cloud using the reshaped points\n",
    "        self.points = greedy_subset_of_data(reshaped_points, surface_variations, M, k_init, k_add)\n",
    "\n",
    "        print(\"Simplified Point Cloud Shape:\", self.points.shape)\n",
    "        print(f\"Loaded {len(self.labels)} training samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.points[idx].astype(np.float32), self.labels[idx]\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for points, labels in train_loader:\n",
    "        points, labels = points.to(device).float(), labels.to(device)  \n",
    "        points = points.permute(0, 2, 1)  # Swap (batch, num_points, 3) -> (batch, 3, num_points)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(points)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader), correct / total_samples\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for points, labels in val_loader:\n",
    "            points, labels = points.to(device).float(), labels.to(device)  \n",
    "            points = points.permute(0, 2, 1)  #  Fix shape\n",
    "            \n",
    "            outputs = model(points)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader), correct / total_samples\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    batch_size = 16\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 75\n",
    "    num_classes = 40\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Dataset paths (adjust as needed)\n",
    "    dataset_paths = [\n",
    "        '/kaggle/input/model40net/modelnet40_hdf5_2048',\n",
    "        '/content/modelnet40_hdf5_2048',\n",
    "        '.'  # Current directory\n",
    "    ]\n",
    "\n",
    "    # Find a valid dataset path\n",
    "    dataset_path = None\n",
    "    for path in dataset_paths:\n",
    "        if os.path.exists(path):\n",
    "            dataset_path = path\n",
    "            print(f\"Using dataset path: {dataset_path}\")\n",
    "            break\n",
    "\n",
    "    if not dataset_path:\n",
    "        raise ValueError(\"Could not find ModelNet40 dataset\")\n",
    "\n",
    "    # Create dataset (only training data)\n",
    "    train_dataset = ModelNet40Dataset(dataset_path, train=True)\n",
    "    \n",
    "    # Create data loader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = PointNetClassification(num_classes=num_classes).to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}')\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'pointnet_modelnet40.pth')\n",
    "    print(\"Model saved to pointnet_modelnet40.pth\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T21:34:55.504032Z",
     "iopub.status.busy": "2025-04-18T21:34:55.503571Z",
     "iopub.status.idle": "2025-04-18T21:34:58.464672Z",
     "shell.execute_reply": "2025-04-18T21:34:58.464034Z",
     "shell.execute_reply.started": "2025-04-18T21:34:55.504009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found dataset at: /kaggle/input/model40net/modelnet40_hdf5_2048\n",
      "Available H5 files: ['train3.h5', 'test1.h5', 'test0.h5', 'train1.h5', 'train4.h5', 'train2.h5', 'train0.h5']\n",
      "Using test files: ['test1.h5', 'test0.h5']\n",
      "Loaded 2048 samples from /kaggle/input/model40net/modelnet40_hdf5_2048/test0.h5\n",
      "Data shape: (2048, 2048, 3), Labels shape: (2048, 1)\n",
      "First 10 labels: [17 17  7 24 22 26  7  2  9 21]\n",
      "Input X shape before conversion: (2048, 2048, 3)\n",
      "Input y shape before conversion: (2048,)\n",
      "Raw tensor shape (should be [N, num_points, 3]): torch.Size([2048, 2048, 3])\n",
      "Transformed tensor shape (should be [N, 3, num_points]): torch.Size([2048, 3, 2048])\n",
      "\n",
      "Starting evaluation...\n",
      "Sample 0: Label=17, Prediction=17, Correct=True\n",
      "Sample 1: Label=17, Prediction=17, Correct=True\n",
      "Sample 2: Label=7, Prediction=7, Correct=True\n",
      "Sample 3: Label=24, Prediction=24, Correct=True\n",
      "Sample 4: Label=22, Prediction=22, Correct=True\n",
      "Sample 5: Label=26, Prediction=26, Correct=True\n",
      "Sample 6: Label=7, Prediction=7, Correct=True\n",
      "Sample 7: Label=2, Prediction=2, Correct=True\n",
      "Sample 8: Label=9, Prediction=9, Correct=True\n",
      "Sample 9: Label=21, Prediction=21, Correct=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/4003296764.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"pointnet_modelnet40.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/2048 samples. Current accuracy: 0.9300\n",
      "Processed 200/2048 samples. Current accuracy: 0.9150\n",
      "Processed 300/2048 samples. Current accuracy: 0.9033\n",
      "Processed 400/2048 samples. Current accuracy: 0.8950\n",
      "Processed 500/2048 samples. Current accuracy: 0.8880\n",
      "Processed 600/2048 samples. Current accuracy: 0.8917\n",
      "Processed 700/2048 samples. Current accuracy: 0.8957\n",
      "Processed 800/2048 samples. Current accuracy: 0.9050\n",
      "Processed 900/2048 samples. Current accuracy: 0.9022\n",
      "Processed 1000/2048 samples. Current accuracy: 0.9070\n",
      "Processed 1100/2048 samples. Current accuracy: 0.9091\n",
      "Processed 1200/2048 samples. Current accuracy: 0.9083\n",
      "Processed 1300/2048 samples. Current accuracy: 0.9077\n",
      "Processed 1400/2048 samples. Current accuracy: 0.9079\n",
      "Processed 1500/2048 samples. Current accuracy: 0.9060\n",
      "Processed 1600/2048 samples. Current accuracy: 0.9081\n",
      "Processed 1700/2048 samples. Current accuracy: 0.9029\n",
      "Processed 1800/2048 samples. Current accuracy: 0.9000\n",
      "Processed 1900/2048 samples. Current accuracy: 0.9000\n",
      "Processed 2000/2048 samples. Current accuracy: 0.9015\n",
      "\n",
      "Overall Test Accuracy: 0.9014 (1846/2048)\n",
      "\n",
      "Per-class accuracy:\n",
      "Class 0: 1.0000 (84/84)\n",
      "Class 1: 0.8974 (35/39)\n",
      "Class 2: 0.9756 (80/82)\n",
      "Class 3: 0.8667 (13/15)\n",
      "Class 4: 0.9375 (75/80)\n",
      "Class 5: 0.9765 (83/85)\n",
      "Class 6: 1.0000 (12/12)\n",
      "Class 7: 0.9882 (84/85)\n",
      "Class 8: 0.9655 (84/87)\n",
      "Class 9: 1.0000 (14/14)\n",
      "\n",
      "Model architecture:\n",
      "PointNetClassification(\n",
      "  (feature_extraction): PointNetFeature(\n",
      "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=40, bias=True)\n",
      "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to load test data from HDF5 with verification steps\n",
    "def load_h5_data(h5_filename):\n",
    "    with h5py.File(h5_filename, 'r') as f:\n",
    "        data = f['data'][:]\n",
    "        labels = f['label'][:]\n",
    "        print(f\"Loaded {len(labels)} samples from {h5_filename}\")\n",
    "        print(f\"Data shape: {data.shape}, Labels shape: {labels.shape}\")\n",
    "        # Print some sample labels to verify\n",
    "        print(f\"First 10 labels: {labels.squeeze()[:10]}\")\n",
    "    return data, labels\n",
    "\n",
    "# Locate test files - make sure we're using different files than training\n",
    "dataset_paths = [\n",
    "    '/kaggle/input/model40net/modelnet40_hdf5_2048',\n",
    "    '/content/modelnet40_hdf5_2048',\n",
    "    '.'  # Current directory\n",
    "]\n",
    "\n",
    "# Find a valid dataset path\n",
    "dataset_path = None\n",
    "for path in dataset_paths:\n",
    "    if os.path.exists(path):\n",
    "        dataset_path = path\n",
    "        print(f\"Found dataset at: {dataset_path}\")\n",
    "        break\n",
    "\n",
    "if not dataset_path:\n",
    "    raise ValueError(\"Could not find ModelNet40 dataset\")\n",
    "\n",
    "# List all HDF5 files to ensure we're using separate test files\n",
    "h5_files = [f for f in os.listdir(dataset_path) if f.endswith('.h5')]\n",
    "print(f\"Available H5 files: {h5_files}\")\n",
    "\n",
    "# Explicitly use test files (not train files)\n",
    "test_files = [f for f in h5_files if f.startswith('test')]\n",
    "if not test_files:\n",
    "    raise ValueError(\"No test files found in the dataset directory\")\n",
    "\n",
    "print(f\"Using test files: {test_files}\")\n",
    "test_h5_file = os.path.join(dataset_path, test_files[1])\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test = load_h5_data(test_h5_file)\n",
    "y_test = np.squeeze(y_test)  # Ensure labels are correctly shaped\n",
    "\n",
    "# Verify input format before conversion\n",
    "print(f\"Input X shape before conversion: {X_test.shape}\")\n",
    "print(f\"Input y shape before conversion: {y_test.shape}\")\n",
    "\n",
    "# Convert to PyTorch tensors WITHOUT transpose to see if that's causing issues\n",
    "X_test_raw = torch.tensor(X_test, dtype=torch.float32)\n",
    "print(f\"Raw tensor shape (should be [N, num_points, 3]): {X_test_raw.shape}\")\n",
    "\n",
    "# Now apply transformation correctly based on model expectation\n",
    "# PointNet expects [batch, channels, num_points]\n",
    "X_test = X_test_raw.permute(0, 2, 1)\n",
    "print(f\"Transformed tensor shape (should be [N, 3, num_points]): {X_test.shape}\")\n",
    "\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Load trained model\n",
    "num_classes = 40\n",
    "model = PointNetClassification(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"pointnet_modelnet40.pth\"))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Perform testing in a single loop with detailed logging\n",
    "correct = 0\n",
    "total = len(y_test)\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "print(\"\\nStarting evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for i in range(total):\n",
    "        # Get a single test sample\n",
    "        sample_X = X_test[i].unsqueeze(0).to(device)\n",
    "        sample_y = y_test[i].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(sample_X)\n",
    "        \n",
    "        # Get prediction\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        prediction = predicted[0]\n",
    "        \n",
    "        # Track correctness\n",
    "        correct_prediction = (prediction == sample_y)\n",
    "        if correct_prediction:\n",
    "            correct += 1\n",
    "            class_correct[sample_y] += 1\n",
    "        class_total[sample_y] += 1\n",
    "        \n",
    "        # Print detailed info for first few samples\n",
    "        if i < 10:\n",
    "            print(f\"Sample {i}: Label={sample_y.item()}, Prediction={prediction.item()}, Correct={correct_prediction.item()}\")\n",
    "        \n",
    "        # Print progress\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Processed {i+1}/{total} samples. Current accuracy: {correct/(i+1):.4f}\")\n",
    "\n",
    "# Compute and print final accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"\\nOverall Test Accuracy: {accuracy:.4f} ({correct}/{total})\")\n",
    "\n",
    "# Print per-class accuracy for the first few classes\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i in range(min(10, num_classes)):\n",
    "    if class_total[i] > 0:\n",
    "        class_acc = class_correct[i] / class_total[i]\n",
    "        print(f\"Class {i}: {class_acc:.4f} ({class_correct[i]}/{class_total[i]})\")\n",
    "\n",
    "# Verify the model architecture\n",
    "print(\"\\nModel architecture:\")\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7184493,
     "sourceId": 11464975,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
